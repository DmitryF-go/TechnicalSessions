{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense,Flatten,Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=MobileNetV2(weights=None,include_top=False, input_shape = (32,32,3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "preds=Dense(10,activation='softmax')(x) #final layer with softmax activation\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "x_train = x_train*1./255\n",
    "x_test = x_test*1./255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clr_callback import CyclicLR\n",
    "clr = CyclicLR(base_lr=0.001, max_lr=0.006, step_size=2000, mode='triangular2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 33, 33, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 16, 16, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           12810       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 2,236,682\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  4/390 [..............................] - ETA: 9:04 - loss: 1.0293 - acc: 0.6406 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taksa\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.132799). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 34s 87ms/step - loss: 0.9820 - acc: 0.6577 - val_loss: 1.6815 - val_acc: 0.5577\n",
      "Epoch 2/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.9832 - acc: 0.6555 - val_loss: 1.5879 - val_acc: 0.5490\n",
      "Epoch 3/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.9822 - acc: 0.6586 - val_loss: 1.3286 - val_acc: 0.5903\n",
      "Epoch 4/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.9940 - acc: 0.6575 - val_loss: 1.5383 - val_acc: 0.5692\n",
      "Epoch 5/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 1.0036 - acc: 0.6502 - val_loss: 1.8148 - val_acc: 0.5428\n",
      "Epoch 6/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.9993 - acc: 0.6519 - val_loss: 2.0314 - val_acc: 0.5110\n",
      "Epoch 7/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.9717 - acc: 0.6602 - val_loss: 2.1964 - val_acc: 0.4876\n",
      "Epoch 8/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.9413 - acc: 0.6741 - val_loss: 2.1759 - val_acc: 0.4877\n",
      "Epoch 9/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.9109 - acc: 0.6838 - val_loss: 1.4113 - val_acc: 0.5958\n",
      "Epoch 10/500\n",
      "390/390 [==============================] - 27s 69ms/step - loss: 0.8903 - acc: 0.6911 - val_loss: 1.1936 - val_acc: 0.6337\n",
      "Epoch 11/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.8668 - acc: 0.7000 - val_loss: 0.9980 - val_acc: 0.6693\n",
      "Epoch 12/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.8709 - acc: 0.6959 - val_loss: 1.0596 - val_acc: 0.6519\n",
      "Epoch 13/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8675 - acc: 0.6982 - val_loss: 1.1689 - val_acc: 0.6234\n",
      "Epoch 14/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8809 - acc: 0.6947 - val_loss: 1.1412 - val_acc: 0.6305\n",
      "Epoch 15/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.8811 - acc: 0.6928 - val_loss: 0.9235 - val_acc: 0.6849\n",
      "Epoch 16/500\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.8931 - acc: 0.6916 - val_loss: 1.4281 - val_acc: 0.5794\n",
      "Epoch 17/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8766 - acc: 0.6937 - val_loss: 1.0899 - val_acc: 0.6443\n",
      "Epoch 18/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8681 - acc: 0.6985 - val_loss: 0.9181 - val_acc: 0.6912\n",
      "Epoch 19/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8429 - acc: 0.7071 - val_loss: 0.9094 - val_acc: 0.6947\n",
      "Epoch 20/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8410 - acc: 0.7081 - val_loss: 0.8606 - val_acc: 0.7039\n",
      "Epoch 21/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8173 - acc: 0.7163 - val_loss: 0.8594 - val_acc: 0.7018\n",
      "Epoch 22/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8134 - acc: 0.7166 - val_loss: 0.9489 - val_acc: 0.6812\n",
      "Epoch 23/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8226 - acc: 0.7173 - val_loss: 0.9448 - val_acc: 0.6791\n",
      "Epoch 24/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8272 - acc: 0.7127 - val_loss: 0.8237 - val_acc: 0.7165\n",
      "Epoch 25/500\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.8230 - acc: 0.7137 - val_loss: 0.8949 - val_acc: 0.6969\n",
      "Epoch 26/500\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.8325 - acc: 0.7105 - val_loss: 0.9401 - val_acc: 0.6867\n",
      "Epoch 27/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8252 - acc: 0.7128 - val_loss: 0.8724 - val_acc: 0.7067\n",
      "Epoch 28/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.8095 - acc: 0.7181 - val_loss: 0.7826 - val_acc: 0.7342\n",
      "Epoch 29/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8049 - acc: 0.7192 - val_loss: 0.8591 - val_acc: 0.7101\n",
      "Epoch 30/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7966 - acc: 0.7238 - val_loss: 0.8582 - val_acc: 0.7068\n",
      "Epoch 31/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7855 - acc: 0.7290 - val_loss: 0.8497 - val_acc: 0.7097\n",
      "Epoch 32/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7819 - acc: 0.7299 - val_loss: 0.9199 - val_acc: 0.6852\n",
      "Epoch 33/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7787 - acc: 0.7302 - val_loss: 0.9013 - val_acc: 0.69670s - loss: 0.7785 - acc: 0.73\n",
      "Epoch 34/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7828 - acc: 0.7297 - val_loss: 0.8344 - val_acc: 0.7112\n",
      "Epoch 35/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7904 - acc: 0.7262 - val_loss: 0.8402 - val_acc: 0.7156\n",
      "Epoch 36/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7819 - acc: 0.7288 - val_loss: 0.8178 - val_acc: 0.7207\n",
      "Epoch 37/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7822 - acc: 0.7296 - val_loss: 0.9219 - val_acc: 0.6880\n",
      "Epoch 38/500\n",
      "390/390 [==============================] - 27s 69ms/step - loss: 0.7777 - acc: 0.7322 - val_loss: 0.9190 - val_acc: 0.6959\n",
      "Epoch 39/500\n",
      "390/390 [==============================] - 26s 68ms/step - loss: 0.7781 - acc: 0.7301 - val_loss: 0.8679 - val_acc: 0.7047\n",
      "Epoch 40/500\n",
      "390/390 [==============================] - 26s 67ms/step - loss: 0.7695 - acc: 0.7289 - val_loss: 0.8404 - val_acc: 0.7131\n",
      "Epoch 41/500\n",
      "390/390 [==============================] - 26s 68ms/step - loss: 0.7647 - acc: 0.7357 - val_loss: 0.8308 - val_acc: 0.7153\n",
      "Epoch 42/500\n",
      "390/390 [==============================] - 26s 67ms/step - loss: 0.7620 - acc: 0.7380 - val_loss: 0.7563 - val_acc: 0.7426\n",
      "Epoch 43/500\n",
      "390/390 [==============================] - 26s 68ms/step - loss: 0.7555 - acc: 0.7391 - val_loss: 0.8490 - val_acc: 0.7089\n",
      "Epoch 44/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.7609 - acc: 0.7388 - val_loss: 0.8150 - val_acc: 0.7179\n",
      "Epoch 45/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7630 - acc: 0.7361 - val_loss: 0.8015 - val_acc: 0.7299\n",
      "Epoch 46/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7587 - acc: 0.7368 - val_loss: 0.7990 - val_acc: 0.7327\n",
      "Epoch 47/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7564 - acc: 0.7380 - val_loss: 0.7411 - val_acc: 0.7517\n",
      "Epoch 48/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7531 - acc: 0.7430 - val_loss: 0.8337 - val_acc: 0.7182\n",
      "Epoch 49/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7501 - acc: 0.7406 - val_loss: 0.7719 - val_acc: 0.7346\n",
      "Epoch 50/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7477 - acc: 0.7394 - val_loss: 0.8280 - val_acc: 0.7222\n",
      "Epoch 51/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7468 - acc: 0.7429 - val_loss: 0.7892 - val_acc: 0.7325\n",
      "Epoch 52/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.7414 - acc: 0.7433 - val_loss: 0.7945 - val_acc: 0.7290 acc: 0\n",
      "Epoch 53/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7362 - acc: 0.7442 - val_loss: 0.8403 - val_acc: 0.7121\n",
      "Epoch 54/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7430 - acc: 0.7414 - val_loss: 0.8554 - val_acc: 0.7128\n",
      "Epoch 55/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7372 - acc: 0.7444 - val_loss: 0.7922 - val_acc: 0.7319\n",
      "Epoch 56/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.7339 - acc: 0.7468 - val_loss: 0.8318 - val_acc: 0.7211\n",
      "Epoch 57/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7399 - acc: 0.7447 - val_loss: 0.8007 - val_acc: 0.7235\n",
      "Epoch 58/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7309 - acc: 0.7483 - val_loss: 0.8881 - val_acc: 0.7051\n",
      "Epoch 59/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7299 - acc: 0.7475 - val_loss: 0.8359 - val_acc: 0.7158\n",
      "Epoch 60/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7332 - acc: 0.7457 - val_loss: 0.8121 - val_acc: 0.7231\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7315 - acc: 0.7474 - val_loss: 0.8123 - val_acc: 0.7231\n",
      "Epoch 62/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7268 - acc: 0.7490 - val_loss: 0.7718 - val_acc: 0.7378\n",
      "Epoch 63/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7274 - acc: 0.7491 - val_loss: 0.7649 - val_acc: 0.7409\n",
      "Epoch 64/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7260 - acc: 0.7501 - val_loss: 0.7465 - val_acc: 0.7440\n",
      "Epoch 65/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7204 - acc: 0.7527 - val_loss: 0.7544 - val_acc: 0.7452\n",
      "Epoch 66/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7198 - acc: 0.7520 - val_loss: 0.8109 - val_acc: 0.7242\n",
      "Epoch 67/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7192 - acc: 0.7496 - val_loss: 0.7598 - val_acc: 0.7417\n",
      "Epoch 68/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7214 - acc: 0.7522 - val_loss: 0.7939 - val_acc: 0.7316\n",
      "Epoch 69/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7152 - acc: 0.7520 - val_loss: 0.7455 - val_acc: 0.7474\n",
      "Epoch 70/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7177 - acc: 0.7520 - val_loss: 0.8143 - val_acc: 0.7264\n",
      "Epoch 71/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7178 - acc: 0.7523 - val_loss: 0.7969 - val_acc: 0.7326\n",
      "Epoch 72/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7161 - acc: 0.7535 - val_loss: 0.7593 - val_acc: 0.7450\n",
      "Epoch 73/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7080 - acc: 0.7549 - val_loss: 0.7465 - val_acc: 0.7466\n",
      "Epoch 74/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7166 - acc: 0.7534 - val_loss: 0.7525 - val_acc: 0.7399\n",
      "Epoch 75/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.7057 - acc: 0.7588 - val_loss: 0.7455 - val_acc: 0.7429\n",
      "Epoch 76/500\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.7081 - acc: 0.7553 - val_loss: 0.8276 - val_acc: 0.7206\n",
      "Epoch 77/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7080 - acc: 0.7554 - val_loss: 0.7631 - val_acc: 0.7455\n",
      "Epoch 78/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7112 - acc: 0.7548 - val_loss: 0.7555 - val_acc: 0.7436s - loss: 0.7117 - \n",
      "Epoch 79/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7080 - acc: 0.7561 - val_loss: 0.7691 - val_acc: 0.7374\n",
      "Epoch 80/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7035 - acc: 0.7585 - val_loss: 0.7826 - val_acc: 0.7341\n",
      "Epoch 81/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7010 - acc: 0.7580 - val_loss: 0.7092 - val_acc: 0.7613\n",
      "Epoch 82/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6999 - acc: 0.7577 - val_loss: 0.7901 - val_acc: 0.7302: 0s - loss: 0.6996 - a\n",
      "Epoch 83/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7072 - acc: 0.7551 - val_loss: 0.7427 - val_acc: 0.7459\n",
      "Epoch 84/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.7041 - acc: 0.7566 - val_loss: 0.7051 - val_acc: 0.7598\n",
      "Epoch 85/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.6945 - acc: 0.7598 - val_loss: 0.8083 - val_acc: 0.7263\n",
      "Epoch 86/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7027 - acc: 0.7556 - val_loss: 0.7720 - val_acc: 0.7397\n",
      "Epoch 87/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6992 - acc: 0.7590 - val_loss: 0.7503 - val_acc: 0.7465\n",
      "Epoch 88/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6997 - acc: 0.7593 - val_loss: 0.8130 - val_acc: 0.7328\n",
      "Epoch 89/500\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.6966 - acc: 0.7596 - val_loss: 0.7952 - val_acc: 0.7328\n",
      "Epoch 90/500\n",
      "390/390 [==============================] - 27s 69ms/step - loss: 0.6964 - acc: 0.7580 - val_loss: 0.8171 - val_acc: 0.7238\n",
      "Epoch 91/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6907 - acc: 0.7611 - val_loss: 0.7659 - val_acc: 0.7402\n",
      "Epoch 92/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6987 - acc: 0.7563 - val_loss: 0.7542 - val_acc: 0.7424\n",
      "Epoch 93/500\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.6958 - acc: 0.7582 - val_loss: 0.8253 - val_acc: 0.7208\n",
      "Epoch 94/500\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 0.6861 - acc: 0.7632 - val_loss: 0.7344 - val_acc: 0.7517\n",
      "Epoch 95/500\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.6892 - acc: 0.7614 - val_loss: 0.7633 - val_acc: 0.7391\n",
      "Epoch 96/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6895 - acc: 0.7608 - val_loss: 0.7924 - val_acc: 0.7334\n",
      "Epoch 97/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6849 - acc: 0.7633 - val_loss: 0.8040 - val_acc: 0.7326\n",
      "Epoch 98/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.6797 - acc: 0.7633 - val_loss: 0.7533 - val_acc: 0.7409\n",
      "Epoch 99/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6894 - acc: 0.7636 - val_loss: 0.7526 - val_acc: 0.7466\n",
      "Epoch 100/500\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.6827 - acc: 0.7646 - val_loss: 0.7444 - val_acc: 0.7475\n",
      "Epoch 101/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.6889 - acc: 0.7638 - val_loss: 0.7488 - val_acc: 0.7455\n",
      "Epoch 102/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6792 - acc: 0.7657 - val_loss: 0.7541 - val_acc: 0.7436\n",
      "Epoch 103/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6780 - acc: 0.7665 - val_loss: 0.7605 - val_acc: 0.7429\n",
      "Epoch 104/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6854 - acc: 0.7629 - val_loss: 0.7653 - val_acc: 0.7425 ETA: 0s - loss: 0.6847\n",
      "Epoch 105/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.6800 - acc: 0.7640 - val_loss: 0.7790 - val_acc: 0.7369\n",
      "Epoch 106/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6767 - acc: 0.7653 - val_loss: 0.8544 - val_acc: 0.7183\n",
      "Epoch 107/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6865 - acc: 0.7640 - val_loss: 0.7488 - val_acc: 0.7434\n",
      "Epoch 108/500\n",
      "390/390 [==============================] - 40s 103ms/step - loss: 0.6782 - acc: 0.7658 - val_loss: 0.7260 - val_acc: 0.7520\n",
      "Epoch 109/500\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.6706 - acc: 0.7687 - val_loss: 0.7098 - val_acc: 0.7534\n",
      "Epoch 110/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6778 - acc: 0.7676 - val_loss: 0.7304 - val_acc: 0.7484\n",
      "Epoch 111/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6806 - acc: 0.7665 - val_loss: 0.7223 - val_acc: 0.7515\n",
      "Epoch 112/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6775 - acc: 0.7659 - val_loss: 0.7600 - val_acc: 0.7462\n",
      "Epoch 113/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6693 - acc: 0.7692 - val_loss: 0.7312 - val_acc: 0.7502\n",
      "Epoch 114/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6662 - acc: 0.7719 - val_loss: 0.7554 - val_acc: 0.7426\n",
      "Epoch 115/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6748 - acc: 0.7669 - val_loss: 0.7825 - val_acc: 0.7337\n",
      "Epoch 116/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6756 - acc: 0.7659 - val_loss: 0.7642 - val_acc: 0.7386\n",
      "Epoch 117/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6670 - acc: 0.7689 - val_loss: 0.8384 - val_acc: 0.7158\n",
      "Epoch 118/500\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.6664 - acc: 0.7674 - val_loss: 0.7210 - val_acc: 0.7554\n",
      "Epoch 119/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6663 - acc: 0.7706 - val_loss: 0.7343 - val_acc: 0.7505 - acc: - ETA: 3s - loss: 0.6615 -\n",
      "Epoch 120/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6689 - acc: 0.7687 - val_loss: 0.7277 - val_acc: 0.7505\n",
      "Epoch 121/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6662 - acc: 0.7693 - val_loss: 0.7510 - val_acc: 0.7444\n",
      "Epoch 122/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6661 - acc: 0.7686 - val_loss: 0.7183 - val_acc: 0.7560\n",
      "Epoch 123/500\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.6660 - acc: 0.7689 - val_loss: 0.7078 - val_acc: 0.7578\n",
      "Epoch 124/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6635 - acc: 0.7712 - val_loss: 0.8262 - val_acc: 0.7187\n",
      "Epoch 125/500\n",
      "390/390 [==============================] - 39s 101ms/step - loss: 0.6576 - acc: 0.7740 - val_loss: 0.7177 - val_acc: 0.7562\n",
      "Epoch 126/500\n",
      "390/390 [==============================] - 33s 85ms/step - loss: 0.6617 - acc: 0.7717 - val_loss: 0.7389 - val_acc: 0.7494\n",
      "Epoch 127/500\n",
      "390/390 [==============================] - 38s 98ms/step - loss: 0.6621 - acc: 0.7712 - val_loss: 0.7563 - val_acc: 0.7431\n",
      "Epoch 128/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.6609 - acc: 0.7702 - val_loss: 0.7235 - val_acc: 0.7535\n",
      "Epoch 129/500\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.6569 - acc: 0.7725 - val_loss: 0.6961 - val_acc: 0.7624\n",
      "Epoch 130/500\n",
      "390/390 [==============================] - 33s 83ms/step - loss: 0.6620 - acc: 0.7729 - val_loss: 0.7442 - val_acc: 0.7514\n",
      "Epoch 131/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.6552 - acc: 0.7732 - val_loss: 0.8216 - val_acc: 0.7267\n",
      "Epoch 132/500\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.6601 - acc: 0.7730 - val_loss: 0.7409 - val_acc: 0.7467\n",
      "Epoch 133/500\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.6559 - acc: 0.7740 - val_loss: 0.7692 - val_acc: 0.7461\n",
      "Epoch 134/500\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.6526 - acc: 0.7751 - val_loss: 0.7271 - val_acc: 0.7547\n",
      "Epoch 135/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6527 - acc: 0.7740 - val_loss: 0.8106 - val_acc: 0.7292\n",
      "Epoch 136/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6614 - acc: 0.7722 - val_loss: 0.7880 - val_acc: 0.7376\n",
      "Epoch 137/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6522 - acc: 0.7751 - val_loss: 0.7906 - val_acc: 0.7358\n",
      "Epoch 138/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6538 - acc: 0.7730 - val_loss: 0.7374 - val_acc: 0.7492\n",
      "Epoch 139/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6498 - acc: 0.7730 - val_loss: 0.7777 - val_acc: 0.7407\n",
      "Epoch 140/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6482 - acc: 0.7754 - val_loss: 0.7329 - val_acc: 0.7504\n",
      "Epoch 141/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6417 - acc: 0.7784 - val_loss: 0.7897 - val_acc: 0.7355\n",
      "Epoch 142/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6549 - acc: 0.7733 - val_loss: 0.7556 - val_acc: 0.7438\n",
      "Epoch 143/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6483 - acc: 0.7777 - val_loss: 0.7583 - val_acc: 0.7443\n",
      "Epoch 144/500\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6487 - acc: 0.7772 - val_loss: 0.7533 - val_acc: 0.7452\n",
      "Epoch 145/500\n",
      "390/390 [==============================] - 27s 68ms/step - loss: 0.6457 - acc: 0.7767 - val_loss: 0.7978 - val_acc: 0.7339\n",
      "Epoch 146/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6443 - acc: 0.7773 - val_loss: 0.7467 - val_acc: 0.7517\n",
      "Epoch 147/500\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.6494 - acc: 0.7762 - val_loss: 0.7643 - val_acc: 0.7425\n",
      "Epoch 148/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6477 - acc: 0.7756 - val_loss: 0.7288 - val_acc: 0.7551\n",
      "Epoch 149/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6410 - acc: 0.7784 - val_loss: 0.7315 - val_acc: 0.7540\n",
      "Epoch 150/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6420 - acc: 0.7754 - val_loss: 0.7821 - val_acc: 0.7437\n",
      "Epoch 151/500\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6422 - acc: 0.7771 - val_loss: 0.7441 - val_acc: 0.7457\n",
      "Epoch 152/500\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6455 - acc: 0.7770 - val_loss: 0.7937 - val_acc: 0.7331\n",
      "Epoch 153/500\n",
      "390/390 [==============================] - 40s 103ms/step - loss: 0.6439 - acc: 0.7782 - val_loss: 0.7228 - val_acc: 0.7587\n",
      "Epoch 154/500\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.6412 - acc: 0.7783 - val_loss: 0.7508 - val_acc: 0.7497\n",
      "Epoch 155/500\n",
      "390/390 [==============================] - 79s 203ms/step - loss: 0.6394 - acc: 0.7792 - val_loss: 0.7742 - val_acc: 0.7423\n",
      "Epoch 156/500\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6393 - acc: 0.7809 - val_loss: 0.7345 - val_acc: 0.7528\n",
      "Epoch 157/500\n",
      "390/390 [==============================] - 41s 105ms/step - loss: 0.6367 - acc: 0.7798 - val_loss: 0.7701 - val_acc: 0.7431\n",
      "Epoch 158/500\n",
      "390/390 [==============================] - 83s 212ms/step - loss: 0.6373 - acc: 0.7782 - val_loss: 0.7589 - val_acc: 0.7477\n",
      "Epoch 159/500\n",
      "390/390 [==============================] - 80s 205ms/step - loss: 0.6343 - acc: 0.7809 - val_loss: 0.7459 - val_acc: 0.7507\n",
      "Epoch 160/500\n",
      "390/390 [==============================] - 74s 189ms/step - loss: 0.6409 - acc: 0.7772 - val_loss: 0.7503 - val_acc: 0.7497\n",
      "Epoch 161/500\n",
      "390/390 [==============================] - 77s 197ms/step - loss: 0.6340 - acc: 0.7803 - val_loss: 0.7271 - val_acc: 0.7562\n",
      "Epoch 162/500\n",
      "390/390 [==============================] - 79s 201ms/step - loss: 0.6315 - acc: 0.7815 - val_loss: 0.7455 - val_acc: 0.7508\n",
      "Epoch 163/500\n",
      "390/390 [==============================] - 78s 200ms/step - loss: 0.6349 - acc: 0.7797 - val_loss: 0.7995 - val_acc: 0.7318\n",
      "Epoch 164/500\n",
      "390/390 [==============================] - 79s 201ms/step - loss: 0.6271 - acc: 0.7854 - val_loss: 0.7146 - val_acc: 0.7580\n",
      "Epoch 165/500\n",
      "390/390 [==============================] - 82s 212ms/step - loss: 0.6363 - acc: 0.7784 - val_loss: 0.7982 - val_acc: 0.7345\n",
      "Epoch 166/500\n",
      "390/390 [==============================] - 81s 208ms/step - loss: 0.6344 - acc: 0.7794 - val_loss: 0.7339 - val_acc: 0.7546\n",
      "Epoch 167/500\n",
      "390/390 [==============================] - 74s 189ms/step - loss: 0.6255 - acc: 0.7830 - val_loss: 0.7527 - val_acc: 0.7469\n",
      "Epoch 168/500\n",
      "390/390 [==============================] - 82s 209ms/step - loss: 0.6310 - acc: 0.7815 - val_loss: 0.7506 - val_acc: 0.7516\n",
      "Epoch 169/500\n",
      "390/390 [==============================] - 72s 185ms/step - loss: 0.6255 - acc: 0.7834 - val_loss: 0.7119 - val_acc: 0.7578\n",
      "Epoch 170/500\n",
      "390/390 [==============================] - 71s 183ms/step - loss: 0.6321 - acc: 0.7825 - val_loss: 0.7539 - val_acc: 0.7491\n",
      "Epoch 171/500\n",
      "390/390 [==============================] - 76s 194ms/step - loss: 0.6295 - acc: 0.7823 - val_loss: 0.7205 - val_acc: 0.7550\n",
      "Epoch 172/500\n",
      "390/390 [==============================] - 71s 183ms/step - loss: 0.6199 - acc: 0.7868 - val_loss: 0.7873 - val_acc: 0.7355\n",
      "Epoch 173/500\n",
      "390/390 [==============================] - 75s 193ms/step - loss: 0.6279 - acc: 0.7836 - val_loss: 0.7756 - val_acc: 0.7402\n",
      "Epoch 174/500\n",
      "390/390 [==============================] - 84s 215ms/step - loss: 0.6236 - acc: 0.7844 - val_loss: 0.8012 - val_acc: 0.7345\n",
      "Epoch 175/500\n",
      "390/390 [==============================] - 86s 221ms/step - loss: 0.6266 - acc: 0.7835 - val_loss: 0.7543 - val_acc: 0.7446\n",
      "Epoch 176/500\n",
      "390/390 [==============================] - 85s 218ms/step - loss: 0.6239 - acc: 0.7850 - val_loss: 0.7602 - val_acc: 0.7432\n",
      "Epoch 177/500\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6233 - acc: 0.7836 - val_loss: 0.7612 - val_acc: 0.7430\n",
      "Epoch 178/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6302 - acc: 0.7825 - val_loss: 0.7495 - val_acc: 0.7457\n",
      "Epoch 179/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6213 - acc: 0.7863 - val_loss: 0.7501 - val_acc: 0.7464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6198 - acc: 0.7853 - val_loss: 0.7537 - val_acc: 0.7482\n",
      "Epoch 181/500\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.6260 - acc: 0.7838 - val_loss: 0.7316 - val_acc: 0.7510\n",
      "Epoch 182/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6279 - acc: 0.7832 - val_loss: 0.8060 - val_acc: 0.7324\n",
      "Epoch 183/500\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.6202 - acc: 0.7842 - val_loss: 0.7797 - val_acc: 0.7393\n",
      "Epoch 184/500\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.6235 - acc: 0.7843 - val_loss: 0.7608 - val_acc: 0.7453\n",
      "Epoch 185/500\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6124 - acc: 0.7877 - val_loss: 0.7434 - val_acc: 0.7530 loss: \n",
      "Epoch 186/500\n",
      "390/390 [==============================] - 34s 87ms/step - loss: 0.6146 - acc: 0.7880 - val_loss: 0.7597 - val_acc: 0.7469\n",
      "Epoch 187/500\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.6189 - acc: 0.7866 - val_loss: 0.8887 - val_acc: 0.7116\n",
      "Epoch 188/500\n",
      "390/390 [==============================] - 33s 83ms/step - loss: 0.6178 - acc: 0.7861 - val_loss: 0.8198 - val_acc: 0.7302\n",
      "Epoch 189/500\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 0.6123 - acc: 0.7888 - val_loss: 0.7511 - val_acc: 0.7492\n",
      "Epoch 190/500\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.6102 - acc: 0.7895 - val_loss: 0.7611 - val_acc: 0.7443\n",
      "Epoch 191/500\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.6094 - acc: 0.7889 - val_loss: 0.7135 - val_acc: 0.7608\n",
      "Epoch 192/500\n",
      "390/390 [==============================] - 64s 165ms/step - loss: 0.6168 - acc: 0.7876 - val_loss: 0.7649 - val_acc: 0.7435\n",
      "Epoch 193/500\n",
      "390/390 [==============================] - 79s 203ms/step - loss: 0.6177 - acc: 0.7872 - val_loss: 0.7429 - val_acc: 0.7538\n",
      "Epoch 194/500\n",
      " 19/390 [>.............................] - ETA: 1:04 - loss: 0.6058 - acc: 0.7924"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-93406fcffb3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n\u001b[0;32m      5\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     verbose=1,validation_data=(x_test,y_test),callbacks=[clr])\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "opt_rms = keras.optimizers.adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=500,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxmodel = winmltools.convert_keras(model, target_opset = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from winmltools.utils import save_model\n",
    "# Save the produced ONNX model in binary format\n",
    "save_model(onnxmodel, 'model.onnx')\n",
    "#save the onnx model to the WPF explore, mark as content and copy when new under properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
